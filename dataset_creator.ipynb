{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_creator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srmt99/stock-market/blob/master/dataset_creator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkhuz0qrc4Xi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Mount Google Drive** (colab only)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WbF-OvTj0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run this cell only when using colab\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "ROOT = '/content/drive'\n",
        "print(ROOT)\n",
        "drive.mount(ROOT, force_remount=True)\n",
        "\n",
        "%mkdir '/content/drive/My Drive/stock-market'\n",
        "%cd '/content/drive/My Drive/stock-market'\n",
        "%mkdir 'data/'\n",
        "%mkdir 'all_records/'\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szvn9uZ1vR6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from tensorflow import keras\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import glob\n",
        "import os\n",
        "import copy\n",
        "import random as rnd\n",
        "import datetime\n",
        "mpl.rcParams['figure.figsize'] = (6, 4)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rt2JhZcvR6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### hyper_Parameters ######\n",
        "data_set_num = 9\n",
        "start_from_market = 100\n",
        "plt.figure(figsize=(10,6))\n",
        "test_split = 0.2\n",
        "future_prediction = 1\n",
        "corr_w = 40\n",
        "w = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK6C_9UveHBz",
        "colab_type": "text"
      },
      "source": [
        "# **Download Data** (colab only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44VRqM8YUH_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uploading the data from github into colab's working space\n",
        "%cd 'data'\n",
        "!wget https://github.com/srmt99/stock-market/blob/master/data/markets.npy?raw=true -O markets.npy\n",
        "!wget https://github.com/srmt99/stock-market/blob/master/data/stocks_1.npy?raw=true -O stocks_1.npy\n",
        "!wget https://github.com/srmt99/stock-market/blob/master/data/stocks_2.npy?raw=true -O stocks_2.npy\n",
        "%cd ..\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiC6k25WvR6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stocks = []\n",
        "for i in np.load(\"data/stocks_1.npy\",allow_pickle=True):\n",
        "    stocks.append(i)\n",
        "for i in np.load(\"data/stocks_2.npy\",allow_pickle=True):\n",
        "    stocks.append(i)\n",
        "stocks = np.array(stocks)\n",
        "markets = np.load(\"data/markets.npy\",allow_pickle=True)\n",
        "                  \n",
        "# extracting minimum market length\n",
        "min_market_len = len(markets[0])\n",
        "for i in markets[1:]:\n",
        "  if len(i)<min_market_len:\n",
        "    min_market_len = len(i)\n",
        "\n",
        "# making all markets of the same length\n",
        "for i in range(len(markets)):\n",
        "  while len(markets[i])>min_market_len:\n",
        "    markets[i] = np.delete(markets[i],0,0)\n",
        "\n",
        "for i in range(len(stocks)):\n",
        "  while len(stocks[i])>min_market_len:\n",
        "    stocks[i] = np.delete(stocks[i],0,0)\n",
        "\n",
        "markets = np.stack(markets,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx8QdzbTvR6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ploting some random stock prices and markets\n",
        "r1 = np.random.randint(len(stocks))\n",
        "r2 = np.random.randint(len(markets))\n",
        "print(r1,r2)\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.plot(stocks[r1][:,1],label=\"stock prices\")\n",
        "plt.plot(markets[r2][:,1],label=\"market\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_sQPbd2vR6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def turn_into_windows(input,kernel):\n",
        "    \"\"\"\n",
        "    this function is used to make windows out of the input array and select a label for each window\n",
        "    input array of shape: (len_input, num_features) is turned into windows of shape: (kernel,num_features)\n",
        "    and a labels is selected for each window , which is a floating point number label is selected\n",
        "    from the second features (arr[...,1]) which here is <CLOSE> price for the NEXT sample\n",
        "    NOTE: every window and it's label is normilized together and the info for denormilizing it is stored in\n",
        "    norm_info, which at this time is not needed therfore is commented.\n",
        "\n",
        "    input: 2D array of (time_samples, features)\n",
        "    kernel: window size\n",
        "\n",
        "    returns: two np.arrays of shape: (len_input - kernel + 1, kernel, num_features) , (len_input - kernel + 1,)\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    # norm_info = []\n",
        "    # j = 0\n",
        "    # j is for counting num(windows) , used for norm_info\n",
        "    for i in range(kernel,len(input)-1):\n",
        "        window = input[i-kernel:i+1,:]\n",
        "        # norm_info.append([np.min(window,0),None])\n",
        "        window = window - np.min(window,0)\n",
        "        # norm_info[j][1] = np.max(window,0)\n",
        "        window = window / np.max(window,0)\n",
        "        data.append(window[:-1,:])\n",
        "        labels.append(window[-1,1])\n",
        "        # j+=1\n",
        "    return np.array(data),np.array(labels).reshape(len(labels),1)\n",
        "\n",
        "def turn_into_windows_multi(input,kernel):\n",
        "  \"\"\"\n",
        "  this function is mush similar to the one above (turn_into_windows)\n",
        "  yet this fucntion was created speceficaly for extracting 2d matrices from all markets as windows.\n",
        "  meaning at each step, we make <num_markets> windows from all market <CLOSE> prices together, which\n",
        "  will increase the speed of creating the records further.\n",
        "  input is a 2d matrix of shape: (num_markets, len_markets) and is turned into 2d matrices\n",
        "  of shape: (num_markets, kernel)\n",
        "  NOTE: all of the data in each matrix of windows, is normilized. the info is stored in norm_info\n",
        "  which is commented at the time being , since there is no use for it.\n",
        "\n",
        "  input: 2d matrix of shape: (num_markets, time_samples)\n",
        "  kernel: window size\n",
        "\n",
        "  returns: a np.array of shape: (len_markets - kernel + 1, num_markets, kernel)\n",
        "  \"\"\"\n",
        "  data = []\n",
        "  norm_info = []\n",
        "  # j = 0\n",
        "  # j is for counting num(windows) , used for norm_info\n",
        "  for i in range(kernel,input.shape[1]-1):\n",
        "    window = input[:,i-kernel:i]\n",
        "    # norm_info.append([np.min(window,1).reshape((len(window),1)),None])\n",
        "    window = window - np.min(window,1).reshape((len(window),1))\n",
        "    # norm_info[j][1] = np.max(window,1).reshape((len(window),1))\n",
        "    window = window / np.max(window,1).reshape((len(window),1))\n",
        "    data.append(window)\n",
        "  return np.array(data)\n",
        "\n",
        "def smooth(input):\n",
        "    output = []\n",
        "    output.append(input[0])\n",
        "    output.append(np.mean([input[0],input[1]]))\n",
        "    for i in range(2,len(input)-2):\n",
        "        mean = np.mean([input[i-2],input[i-1],input[i],input[i+1],input[i+2]])\n",
        "        output.append(mean)\n",
        "    output.append(np.mean([input[len(input)-2],input[len(input)-1]]))\n",
        "    output.append(input[len(input)-1])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPdHPNqEvR63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "this part, creates the records and saves them as np.array into files\n",
        "it itreates over stocks, one stock at a time, the stock is first turend into windows\n",
        "of shape: (corr_w,) holding <CLOSE> price in a list of windows. these windows are used\n",
        "to calculate the correlation with the coresponding market windows of shape: (num_mrkets,corr_w)\n",
        "meaning the correalation of each stock window is calculataed against all markets at the same time\n",
        "then, both the stock and markets are turned into windows of length <w> to be put into the records\n",
        "togrther with the before calculated correlations.\n",
        "\"\"\"\n",
        "for count,stock in enumerate(stocks):\n",
        "  records = []\n",
        "  labels = []\n",
        "  correlations = []\n",
        "  x,y = turn_into_windows(stock,corr_w)\n",
        "  for wc,window in enumerate(x[:,:,1]):\n",
        "    corr = np.corrcoef(window,markets[: , min_market_len - len(x) - corr_w - 1 + wc : min_market_len - len(x) + wc -1 , 1])[1:,0]\n",
        "    correlations.append( np.nan_to_num(corr) )\n",
        "  correlations = np.array(correlations)\n",
        "  x,y = turn_into_windows(stock,w)\n",
        "  x2 = turn_into_windows_multi(markets[:,:,1],w)\n",
        "  for wc in range(len(correlations),w,-1):\n",
        "      record = np.zeros( (2*len(markets)+5,w) )\n",
        "      record[:5,:] = np.transpose(x[wc + (len(x)-len(correlations)-1) ][:,1:]) # part 1\n",
        "      record[5:5+len(markets)] = np.transpose(correlations[wc-w:wc]) # part 2\n",
        "      record[5+len(markets):5+2*len(markets)] = x2[wc + (len(x2)-len(correlations)-1)] # part 3\n",
        "      records.append(record)\n",
        "      labels.append(y[wc + (len(x)-len(correlations)-1) ])\n",
        "  np.save(f\"all_records/records_{count}\",np.array([records,labels]))\n",
        "  print(f\"{count}/{len(stocks)}\")\n",
        "print(\"__done__\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRv4HKZPvR67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = []\n",
        "labels = []\n",
        "for count,filename in enumerate(glob.glob(\"all_records/records_*.npy\")):\n",
        "  x,y = np.load(filename,allow_pickle=True)\n",
        "  for i in x:\n",
        "    train.append(i)\n",
        "  for i in y:\n",
        "    labels.append(i[0])\n",
        "  if count == 300:\n",
        "    break\n",
        "\n",
        "train = np.array(train)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnpGMs-GvR6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" \n",
        "We split data into 3 parts: train, validation, test\n",
        "We control the number of records in each set using\n",
        "test_split and val_split\n",
        "\"\"\"\n",
        "val_split, test_split = 0.1, 0.2\n",
        "data = train\n",
        "num_val, num_test = int(val_split * data.shape[0]), int(test_split * data.shape[0])\n",
        "\n",
        "train_x = data[:-(num_val + num_test)]\n",
        "train_y = labels[:-(num_val + num_test)]\n",
        "val_x = data[-(num_val + num_test):-num_test]\n",
        "val_y = labels[-(num_val + num_test):-num_test]\n",
        "test_x = data[-num_test:]\n",
        "test_y = labels[-num_test:]\n",
        "\n",
        "print('train_x:', train_x.shape)\n",
        "print('train_y:', train_y.shape)\n",
        "print('val_x:', val_x.shape)\n",
        "print('val_y:', val_y.shape)\n",
        "print('test_x:', test_x.shape)\n",
        "print('test_y:', test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYAsM6K5vR7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "In this cell we build tf.data.Dataset\n",
        "from numpy arrays\n",
        "\"\"\"\n",
        "batch_size = 16\n",
        "\n",
        "train = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "train = train.shuffle(1024).batch(batch_size).repeat()\n",
        "print('train dataset built')\n",
        "val = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
        "val = val.shuffle(1024).batch(batch_size).repeat()\n",
        "print('validation dataset built')\n",
        "test = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "test = test.shuffle(1024).batch(batch_size)\n",
        "print('test dataset built')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Y3v_I4vR7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Here is the defintion of some callbacks\n",
        "\"\"\"\n",
        "\n",
        "# tensorboard callback\n",
        "log_dir = '.\\\\logs\\\\fit\\\\' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# checkpoint callback\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath='.\\\\checkpoints\\\\model_{epoch}',\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor='val_loss',\n",
        "                                                      verbose=0)\n",
        "# earlystopping callback\n",
        "earlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                          min_delta=0.001,\n",
        "                                                          patience=3,\n",
        "                                                          restore_best_weights=True,)\n",
        "\n",
        "# TerminateOnNaN callback\n",
        "terminateonNaN_callback = tf.keras.callbacks.TerminateOnNaN()\n",
        "\n",
        "# custom callback to save the weights after each batch training\n",
        "# we'll monitor the weights better this way\n",
        "saveweights_callback = keras.callbacks.LambdaCallback(on_batch_end=lambda batch,logs:\\\n",
        "                                                                weights_history.append(model.get_weights()) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKeeNTWNvR7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Building and training a model\n",
        "\"\"\"\n",
        "lstm1_out = 30\n",
        "dense1_out = 100\n",
        "dense2_out = 1\n",
        "num_epoch = 10\n",
        "alpha = 0.001\n",
        "reg = 0.1\n",
        "\n",
        "model = keras.Sequential([\n",
        "  keras.layers.LSTM(lstm1_out, input_shape=train_x[0].shape, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=reg,l2=reg)),\n",
        "  keras.layers.Dense(dense1_out, kernel_regularizer=keras.regularizers.l1_l2(l1=reg,l2=reg)),\n",
        "  keras.layers.Dense(dense2_out, kernel_regularizer=keras.regularizers.l1_l2(l1=reg,l2=reg))\n",
        "])\n",
        "weights_history = []\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=alpha),\n",
        "              loss='mse',\n",
        "              metrics=['mse', 'mae'])\n",
        "history = model.fit(train, validation_data=val, validation_steps=10, epochs=num_epoch, steps_per_epoch=1,\n",
        "                    callbacks=[tensorboard_callback,\n",
        "                               checkpoint_callback,\n",
        "                               earlystopping_callback,\n",
        "                               terminateonNaN_callback,\n",
        "                               saveweights_callback])\n",
        "\n",
        "print(\"evaluating on test set\")\n",
        "model.evaluate(test,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kuLZHwQy7O5Y",
        "colab": {}
      },
      "source": [
        "# !!!! 107 rows which one is for close prices? ----> FIRST row (arr[0,:])\n",
        "\n",
        "\"\"\"\n",
        "In this section we randomly plot the results of\n",
        "predictions on 1 example from both validation and test sets. \n",
        "\"\"\"\n",
        "\n",
        "val_sample = rnd.randint(1, val_x[0].shape[0] - 1)\n",
        "x1 = val_x[val_sample, :, :].reshape(1, val_x.shape[1], -1)\n",
        "y1 = val_y[val_sample]\n",
        "train_sample = rnd.randint(1, train_x[0].shape[0] - 1)\n",
        "x2 = train_x[train_sample, :, :].reshape(1, train_x.shape[1], -1)\n",
        "y2 = train_y[train_sample]\n",
        "\n",
        "yprime1 = model.predict(x1)\n",
        "yprime2 = model.predict(x2)\n",
        "\n",
        "x_axis = [i for i in range(w + 1)]\n",
        "fig, a = plt.subplots(2, 1)\n",
        "a[0].plot(x_axis[:-1], x1[0, 0, :], 'bo', label='history')\n",
        "a[0].plot(x_axis[-1:], y1, 'ro', label='real')\n",
        "a[0].plot(x_axis[-1:], yprime1, 'go', label='prediction')\n",
        "a[0].legend()\n",
        "a[0].set_title('Validation Set')\n",
        "a[1].plot(x_axis[:-1], x2[0, 0, :], 'bo', label='history')\n",
        "a[1].plot(x_axis[-1:], y2, 'ro', label='real')\n",
        "a[1].plot(x_axis[-1:], yprime2, 'go', label='prediction')\n",
        "a[1].legend()\n",
        "a[1].set_title('Train Set')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpt8lLQXvR7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}