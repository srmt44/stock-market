{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "dataset_creator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srmt99/stock-market/blob/master/dataset_creator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTmsNcQmk3cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from tensorflow import keras\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import glob\n",
        "import os\n",
        "import copy\n",
        "mpl.rcParams['figure.figsize'] = (6, 4)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1-kyGvwk3cT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### hyper_Parameters ######\n",
        "data_set_num = 9\n",
        "start_from_market = 100\n",
        "plt.figure(figsize=(10,6))\n",
        "test_split = 0.2\n",
        "future_prediction = 1\n",
        "corr_w = 40\n",
        "w = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDE7v4uelnDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/srmt99/stock-market/blob/master/data/markets.npy?raw=true\n",
        "!wget https://github.com/srmt99/stock-market/blob/master/data/stocks_1.npy?raw=true\n",
        "!wget https://github.com/srmt99/stock-market/blob/master/data/stocks_2.npy?raw=true\n",
        "\n",
        "stocks = []\n",
        "for i in np.load(\"stocks_1.npy?raw=true\",allow_pickle=True):\n",
        "  stocks.append(i)\n",
        "for i in np.load(\"stocks_2.npy?raw=true\",allow_pickle=True):\n",
        "  stocks.append(i)\n",
        "stocks = np.array(stocks)\n",
        "markets = np.load(\"markets.npy?raw=true\",allow_pickle=True)\n",
        "\n",
        "min_market_len = len(markets[0])\n",
        "for i in markets[1:]:\n",
        "  if len(i)<min_market_len:\n",
        "    min_market_len = len(i)\n",
        "\n",
        "for i in range(len(markets)):\n",
        "  while len(markets[i])>min_market_len:\n",
        "    markets[i] = np.delete(markets[i],0,0)\n",
        "\n",
        "for i in range(len(stocks)):\n",
        "  while len(stocks[i])>min_market_len:\n",
        "    stocks[i] = np.delete(stocks[i],0,0)\n",
        "\n",
        "markets = np.stack(markets,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBYSF94Lk3cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ploting some random stock prices and markets\n",
        "r1 = np.random.randint(len(stocks))\n",
        "r2 = np.random.randint(len(markets))\n",
        "print(r1,r2)\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.plot(stocks[r1][:,1],label=\"stock prices\")\n",
        "plt.plot(markets[r2][:,1],label=\"market\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm-NApUyzc1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def turn_to_windows(input,kernel,future):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for i in range(kernel,len(input)-future):\n",
        "        data.append(input[i-kernel:i,:])\n",
        "        labels.append(input[i:i+future,1])\n",
        "    return np.array(data),np.array(labels).reshape(len(labels),future)\n",
        "\n",
        "def turn_to_windows_multi(input,kernel):\n",
        "  data = []\n",
        "  for i in range(kernel,input.shape[1]-1):\n",
        "        data.append(input[:,i-kernel:i])\n",
        "  return np.array(data)\n",
        "\n",
        "def smooth(input):\n",
        "    output = []\n",
        "    output.append(input[0])\n",
        "    output.append(np.mean([input[0],input[1]]))\n",
        "    for i in range(2,len(input)-2):\n",
        "        mean = np.mean([input[i-2],input[i-1],input[i],input[i+1],input[i+2]])\n",
        "        output.append(mean)\n",
        "    output.append(np.mean([input[len(input)-2],input[len(input)-1]]))\n",
        "    output.append(input[len(input)-1])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98c9uk1qK1Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for count,stock in enumerate(stocks):\n",
        "  records = []\n",
        "  labels = []\n",
        "  correlations = []\n",
        "  x,y = turn_to_windows(stock,corr_w,1)\n",
        "  for wc,window in enumerate(x[:,:,1]):\n",
        "    corr = np.corrcoef(window,markets[: , min_market_len - len(x) - corr_w - 1 + wc : min_market_len - len(x) + wc -1 , 1])[1:,0]\n",
        "    correlations.append( np.nan_to_num(corr) )\n",
        "  correlations = np.array(correlations)\n",
        "  x,y = turn_to_windows(stock,w,1)\n",
        "  x2 = turn_to_windows_multi(markets[:,:,1],w)\n",
        "  for wc in range(len(correlations),w,-1):\n",
        "      record = np.zeros( (2*len(markets)+5,w) )\n",
        "      record[:5,:] = np.transpose(x[wc + (len(x)-len(correlations)-1) ][:,1:]) # part 1\n",
        "      record[5:5+len(markets)] = np.transpose(correlations[wc-w:wc]) # part 2\n",
        "      record[5+len(markets):5+2*len(markets)] = x2[wc + (len(x2)-len(correlations)-1)] # part 3\n",
        "      records.append(record)\n",
        "      labels.append(y[wc + (len(x)-len(correlations)-1) ])\n",
        "  np.save(f\"records_{count}\",np.array([records,labels]))\n",
        "  print(f\"{count}/{len(stocks)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YugA9ZjD2XuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = []\n",
        "labels = []\n",
        "for count,filename in enumerate(glob.glob(\"records_*.npy\")):\n",
        "  x,y = np.load(filename,allow_pickle=True)\n",
        "  for i in x:\n",
        "    train.append(i)\n",
        "  for i in y:\n",
        "    labels.append(i[0])\n",
        "  if count == 30:\n",
        "    break\n",
        "\n",
        "train = np.array(train)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjuC3AGd7bsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" \n",
        "We split data into 3 parts: train, validation, test\n",
        "We control the number of records in each set using\n",
        "test_split and val_split\n",
        "\"\"\"\n",
        "val_split, test_split = 0.1, 0.2\n",
        "data = train\n",
        "num_val, num_test = int(val_split * data.shape[0]), int(test_split * data.shape[0])\n",
        "\n",
        "train_x = data[:-(num_val + num_test)]\n",
        "train_y = labels[:-(num_val + num_test)]\n",
        "val_x = data[-(num_val + num_test):-num_test]\n",
        "val_y = labels[-(num_val + num_test):-num_test]\n",
        "test_x = data[-num_test:]\n",
        "test_y = labels[-num_test:]\n",
        "\n",
        "print('train_x:', train_x.shape)\n",
        "print('train_y:', train_y.shape)\n",
        "print('val_x:', val_x.shape)\n",
        "print('val_y:', val_y.shape)\n",
        "print('test_x:', test_x.shape)\n",
        "print('test_y:', test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av0p6ZlufaFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mean = np.mean(train,(0,2)).reshape(1,105,1)\n",
        "train_std = np.std(train,(0,2)).reshape(1,105,1)\n",
        "labels_mean = np.mean(labels)\n",
        "labels_std = np.std(labels)\n",
        "\n",
        "train = (train - train_mean) / train_std\n",
        "labels = (labels - labels_mean) / labels_std\n",
        "\n",
        "test_size = np.floor(test_split*len(train))\n",
        "\n",
        "train_set = tf.data.Dataset.from_tensor_slices((train,labels))\n",
        "train_set = train_set.shuffle(10000)\n",
        "test_set = train_set.take(test_size).batch(256)\n",
        "train_set = train_set.skip(test_size)\n",
        "train_set = train_set.batch(256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Jd2YiH2YlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Building and training a model\n",
        "\"\"\"\n",
        "lstm1_out = 30\n",
        "dense1_out = 100\n",
        "dense2_out = 1\n",
        "num_epoch = 10\n",
        "alpha = 0.001\n",
        "\n",
        "model = keras.Sequential([\n",
        "  keras.layers.LSTM(lstm1_out, input_shape=train[0].shape, activation='relu'),\n",
        "  keras.layers.Dense(dense1_out),\n",
        "  keras.layers.Dense(dense2_out)\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=alpha),\n",
        "              loss='mse',\n",
        "              metrics=['mse', 'mae'])\n",
        "history = model.fit(train_set, epochs=num_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuLZHwQy7O5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(train[0].reshape(1,105,30)),labels[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuR6Gd1aIgCC",
        "colab_type": "text"
      },
      "source": [
        "**Notes**\n",
        "\n",
        "1 - Clear outputs before committing changes"
      ]
    }
  ]
}