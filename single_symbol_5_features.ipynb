{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "mpl.rcParams['figure.figsize'] = (10, 8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data_csv is a list of 10 data frames holding a [2,] list for each symboL\n",
    "the first one (for example data_csv[i][0] ) is the name of the symbol and\n",
    "the second one (for example data_csv[i][1] ) is the data assosiated to it\n",
    "\"\"\"\n",
    "data_csv = []\n",
    "i = 0\n",
    "for filename in glob.glob('data/*.csv'):\n",
    "    data_csv.append([filename[5:len(filename)-4],pd.read_csv(filename).drop(\"<TICKER>\",1)])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>&lt;OPEN&gt;</th>\n      <th>&lt;CLOSE&gt;</th>\n      <th>&lt;HIGH&gt;</th>\n      <th>&lt;LOW&gt;</th>\n      <th>&lt;VOL&gt;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4000.0</td>\n      <td>3704.0</td>\n      <td>4000.0</td>\n      <td>3600.0</td>\n      <td>172898994</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3778.0</td>\n      <td>3778.0</td>\n      <td>3778.0</td>\n      <td>3778.0</td>\n      <td>10826496</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3853.0</td>\n      <td>3853.0</td>\n      <td>3853.0</td>\n      <td>3853.0</td>\n      <td>26850133</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3930.0</td>\n      <td>3930.0</td>\n      <td>3930.0</td>\n      <td>3930.0</td>\n      <td>31086849</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4008.0</td>\n      <td>4008.0</td>\n      <td>4008.0</td>\n      <td>4008.0</td>\n      <td>40645528</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   <OPEN>  <CLOSE>  <HIGH>   <LOW>      <VOL>\n0  4000.0   3704.0  4000.0  3600.0  172898994\n1  3778.0   3778.0  3778.0  3778.0   10826496\n2  3853.0   3853.0  3853.0  3853.0   26850133\n3  3930.0   3930.0  3930.0  3930.0   31086849\n4  4008.0   4008.0  4008.0  4008.0   40645528"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = 2\n",
    "features = data_csv[data_frame][1][['<OPEN>', '<CLOSE>', '<HIGH>', '<LOW>', '<VOL>']]\n",
    "features.head()\n",
    "# print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_windows(input,kernel):\n",
    "    \"\"\"\n",
    "    Suppose that input is (T, F): T is the number of time steps and F is the number of features\n",
    "    Then this function creates a list of data, label pairs in which data is (N, K, F) and label is (N, F)\n",
    "    N is the number of data, label pairs\n",
    "\n",
    "    Inputs:\n",
    "    - input: (T, F)\n",
    "    - kernel: scalar and we call it K\n",
    "\n",
    "    Outputs:\n",
    "    - data: (N, K, F)\n",
    "    - labels: (N, F)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i in range(0,len(input)-kernel):\n",
    "        data.append(input[i:i+kernel])\n",
    "        labels.append(input[i+kernel])\n",
    "    return np.array(data),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(2420, 20, 5) (2420, 5)\n(606, 20, 5) (606, 5)\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section we prepare the data that we are going to use later.\n",
    "We have train data and validation data.\n",
    "80 percent of the data are for training and we use the rest for validation.\n",
    "\"\"\"\n",
    "data, labels = turn_to_windows(features.values,20)\n",
    "num_train = int(data.shape[0] * 0.8)\n",
    "\n",
    "mask = np.arange(data.shape[0])\n",
    "np.random.shuffle(mask)\n",
    "train_mask = mask[:num_train]\n",
    "val_mask = mask[num_train:]\n",
    "\n",
    "x_train = data[train_mask, :, :]\n",
    "y_train = labels[train_mask, :]\n",
    "x_val = data[val_mask, :, :]\n",
    "y_val = labels[val_mask, :]\n",
    "\n",
    "x_train_std, x_train_mean = np.std(x_train, axis=0), np.mean(x_train, axis=0)\n",
    "y_train_std, y_train_mean = np.std(y_train, axis=0), np.mean(y_train, axis=0)\n",
    "x_val_std, x_val_mean = np.std(x_val, axis=0), np.mean(x_val, axis=0)\n",
    "y_val_std, y_val_mean = np.std(y_val, axis=0), np.mean(y_val, axis=0)\n",
    "\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "y_train = (y_train - y_train_mean) / y_train_std\n",
    "x_val = (x_val - x_val_mean) / x_val_std\n",
    "y_val = (y_val - y_val_mean) / y_val_std\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this section we define some hyperparameters\n",
    "and later use it in tensorboard. \n",
    "\"\"\"\n",
    "HP_LSTM1_OUT = hp.HParam('lstm1_out', hp.Discrete([100, 50]))\n",
    "HP_LSTM2_OUT = hp.HParam('lstm2_out', hp.Discrete([20, 10]))\n",
    "METRIC = 'loss'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LSTM1_OUT, HP_LSTM2_OUT],\n",
    "        metrics=[hp.Metric(METRIC, display_name='Loss')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(hparams):\n",
    "    \"\"\"\n",
    "    This function creates and trains a model with given hyperparameters \n",
    "    and returns the final loss.\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        # keras.layers.LSTM(hparams[HP_LSTM1_OUT], activation='relu', input_shape=data[0].shape, return_sequences=True),\n",
    "        keras.layers.LSTM(hparams[HP_LSTM1_OUT], activation='relu'),\n",
    "        keras.layers.Dense(y_train.shape[1])\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    model.fit(x_train, y_train, epochs=150, batch_size=32, validation_data=(x_val, y_val))\n",
    "    loss = model.evaluate(x_val, y_val)\n",
    "    return loss, model\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "    \"\"\"\n",
    "    This function tests one set of hyperparameters\n",
    "    and saves the result in log directory.\n",
    "    \"\"\"\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)                                         # record the values used in this trial\n",
    "        loss, _ = train_eval_model(hparams)\n",
    "        tf.summary.scalar('loss', loss, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "===============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 1ms/sample - loss: 0.0273\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section we try all different combinations of hyperparameters\n",
    "and save the results.\n",
    "Later we can use tensorboard to visualize these logs.\n",
    "\"\"\"\n",
    "session_num = 0\n",
    "for lstm1_out in HP_LSTM1_OUT.domain.values:\n",
    "    for lstm2_out in HP_LSTM2_OUT.domain.values:\n",
    "        hparams = {\n",
    "            HP_LSTM1_OUT: lstm1_out,\n",
    "            HP_LSTM2_OUT: lstm2_out\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Initiating ...\nTrain on 2420 samples, validate on 606 samples\nEpoch 1/150\n2420/2420 [==============================] - 4s 2ms/sample - loss: 0.3121 - val_loss: 0.1496\nEpoch 2/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.1423 - val_loss: 0.1260\nEpoch 3/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.1291 - val_loss: 0.1178\nEpoch 4/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.1205 - val_loss: 0.1111\nEpoch 5/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.1125 - val_loss: 0.1103\nEpoch 6/150\n2420/2420 [==============================] - 2s 988us/sample - loss: 0.1076 - val_loss: 0.1036\nEpoch 7/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.1035 - val_loss: 0.1043\nEpoch 8/150\n2420/2420 [==============================] - 2s 1000us/sample - loss: 0.1008 - val_loss: 0.0966\nEpoch 9/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0991 - val_loss: 0.0991\nEpoch 10/150\n2420/2420 [==============================] - 2s 974us/sample - loss: 0.0960 - val_loss: 0.0992\nEpoch 11/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0960 - val_loss: 0.0968\nEpoch 12/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0947 - val_loss: 0.0953\nEpoch 13/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0938 - val_loss: 0.0929\nEpoch 14/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0929 - val_loss: 0.0943\nEpoch 15/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0923 - val_loss: 0.0930\nEpoch 16/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0912 - val_loss: 0.0933\nEpoch 17/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0914 - val_loss: 0.0926\nEpoch 18/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.0915 - val_loss: 0.0949\nEpoch 19/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0912 - val_loss: 0.0923\nEpoch 20/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.0911 - val_loss: 0.0934\nEpoch 21/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0919 - val_loss: 0.0947\nEpoch 22/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0898 - val_loss: 0.0974\nEpoch 23/150\n2420/2420 [==============================] - 2s 988us/sample - loss: 0.0898 - val_loss: 0.0911\nEpoch 24/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0897 - val_loss: 0.0907\nEpoch 25/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.0896 - val_loss: 0.0915\nEpoch 26/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.0894 - val_loss: 0.0902\nEpoch 27/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.0894 - val_loss: 0.0937\nEpoch 28/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.0893 - val_loss: 0.0912\nEpoch 29/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0899 - val_loss: 0.0924\nEpoch 30/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0893 - val_loss: 0.0926\nEpoch 31/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0883 - val_loss: 0.0894\nEpoch 32/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0881 - val_loss: 0.0911\nEpoch 33/150\n2420/2420 [==============================] - 2s 1ms/sample - loss: 0.0889 - val_loss: 0.0915\nEpoch 34/150\n2420/2420 [==============================] - 3s 1ms/sample - loss: 0.0882 - val_loss: 0.0892\nEpoch 35/150\n1888/2420 [======================>.......] - ETA: 0s - loss: 0.0900"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-31a506b688d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Initiating ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_eval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'final validation loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-ea5601e93bf0>\u001b[0m in \u001b[0;36mtrain_eval_model\u001b[1;34m(hparams)\u001b[0m\n\u001b[0;32m     11\u001b[0m     ])\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\cs231n\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After testing hyperparameters now its time to\n",
    "train the model with the best set of hyperparameters.\n",
    "\"\"\"\n",
    "hparams = {\n",
    "    HP_LSTM1_OUT: 50,\n",
    "    HP_LSTM2_OUT: 10\n",
    "}\n",
    "print('Initiating ...')\n",
    "loss, model = train_eval_model(hparams)\n",
    "print('final validation loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x1739b227240>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"469.458125pt\" version=\"1.1\" viewBox=\"0 0 608.35 469.458125\" width=\"608.35pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 469.458125 \r\nL 608.35 469.458125 \r\nL 608.35 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 39.65 445.58 \r\nL 597.65 445.58 \r\nL 597.65 10.7 \r\nL 39.65 10.7 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"PathCollection_1\">\r\n    <defs>\r\n     <path d=\"M 0 1.224745 \r\nC 0.324806 1.224745 0.636353 1.095698 0.866025 0.866025 \r\nC 1.095698 0.636353 1.224745 0.324806 1.224745 0 \r\nC 1.224745 -0.324806 1.095698 -0.636353 0.866025 -0.866025 \r\nC 0.636353 -1.095698 0.324806 -1.224745 0 -1.224745 \r\nC -0.324806 -1.224745 -0.636353 -1.095698 -0.866025 -0.866025 \r\nC -1.095698 -0.636353 -1.224745 -0.324806 -1.224745 0 \r\nC -1.224745 0.324806 -1.095698 0.636353 -0.866025 0.866025 \r\nC -0.636353 1.095698 -0.324806 1.224745 0 1.224745 \r\nz\r\n\" id=\"mcccaa5c4df\" style=\"stroke:#1f77b4;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#p16606ca04b)\">\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"324.847871\" xlink:href=\"#mcccaa5c4df\" y=\"265.408426\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"337.839583\" xlink:href=\"#mcccaa5c4df\" y=\"259.72208\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"350.831295\" xlink:href=\"#mcccaa5c4df\" y=\"250.769999\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"363.823006\" xlink:href=\"#mcccaa5c4df\" y=\"240.426988\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"376.814718\" xlink:href=\"#mcccaa5c4df\" y=\"229.207067\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"389.80643\" xlink:href=\"#mcccaa5c4df\" y=\"217.305499\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"402.798141\" xlink:href=\"#mcccaa5c4df\" y=\"204.728473\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"415.789853\" xlink:href=\"#mcccaa5c4df\" y=\"191.28637\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"428.781565\" xlink:href=\"#mcccaa5c4df\" y=\"177.375029\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"441.773277\" xlink:href=\"#mcccaa5c4df\" y=\"163.086456\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"454.764988\" xlink:href=\"#mcccaa5c4df\" y=\"148.600764\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"467.7567\" xlink:href=\"#mcccaa5c4df\" y=\"134.117184\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"480.748412\" xlink:href=\"#mcccaa5c4df\" y=\"119.754846\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"493.740124\" xlink:href=\"#mcccaa5c4df\" y=\"105.655489\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"506.731835\" xlink:href=\"#mcccaa5c4df\" y=\"91.838812\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"519.723547\" xlink:href=\"#mcccaa5c4df\" y=\"78.454854\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"532.715259\" xlink:href=\"#mcccaa5c4df\" y=\"65.60396\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"545.706971\" xlink:href=\"#mcccaa5c4df\" y=\"53.161064\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"558.698682\" xlink:href=\"#mcccaa5c4df\" y=\"41.546907\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"571.690394\" xlink:href=\"#mcccaa5c4df\" y=\"30.638429\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mfdc1990a82\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.013636\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(61.832386 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.972195\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(126.790945 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.930754\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(188.568254 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"259.889312\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(253.526812 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"324.847871\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(318.485371 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"389.80643\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(383.44393 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"454.764988\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(448.402488 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"519.723547\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 35 -->\r\n      <g transform=\"translate(513.361047 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"584.682106\" xlink:href=\"#mfdc1990a82\" y=\"445.58\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(578.319606 460.178437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_10\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m34608d0f5f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m34608d0f5f\" y=\"444.791393\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 2400 -->\r\n      <g transform=\"translate(7.2 448.590612)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m34608d0f5f\" y=\"360.441768\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 2600 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 364.240987)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m34608d0f5f\" y=\"276.092144\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 2800 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 279.891363)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m34608d0f5f\" y=\"191.742519\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 3000 -->\r\n      <g transform=\"translate(7.2 195.541738)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m34608d0f5f\" y=\"107.392895\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 3200 -->\r\n      <g transform=\"translate(7.2 111.192114)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m34608d0f5f\" y=\"23.04327\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 3400 -->\r\n      <g transform=\"translate(7.2 26.842489)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#p16606ca04b)\" d=\"M 65.013636 322.062689 \r\nL 78.005348 341.463103 \r\nL 90.99706 346.945828 \r\nL 103.988772 335.136881 \r\nL 116.980483 347.789325 \r\nL 129.972195 353.27205 \r\nL 142.963907 343.571843 \r\nL 155.955619 344.837088 \r\nL 168.94733 360.863516 \r\nL 181.939042 350.319813 \r\nL 194.930754 360.02002 \r\nL 207.922465 346.945828 \r\nL 220.914177 360.441768 \r\nL 233.905889 352.006806 \r\nL 246.897601 352.428554 \r\nL 259.889312 356.224287 \r\nL 272.881024 377.311693 \r\nL 285.872736 367.611486 \r\nL 298.864448 360.441768 \r\nL 311.856159 360.441768 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p16606ca04b)\" d=\"M 324.847871 349.898065 \r\nL 337.839583 335.558629 \r\nL 350.831295 335.136881 \r\nL 363.823006 321.219193 \r\nL 376.814718 345.680584 \r\nL 389.80643 342.728347 \r\nL 402.798141 350.741561 \r\nL 415.789853 346.945828 \r\nL 428.781565 349.898065 \r\nL 441.773277 352.006806 \r\nL 454.764988 352.006806 \r\nL 467.7567 362.550509 \r\nL 480.748412 373.094212 \r\nL 493.740124 373.937708 \r\nL 506.731835 397.555603 \r\nL 519.723547 425.812727 \r\nL 532.715259 405.568817 \r\nL 545.706971 403.460077 \r\nL 558.698682 403.038329 \r\nL 571.690394 415.269024 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 39.65 445.58 \r\nL 39.65 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 597.65 445.58 \r\nL 597.65 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 39.65 445.58 \r\nL 597.65 445.58 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 39.65 10.7 \r\nL 597.65 10.7 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 46.65 48.05625 \r\nL 101.607813 48.05625 \r\nQ 103.607813 48.05625 103.607813 46.05625 \r\nL 103.607813 17.7 \r\nQ 103.607813 15.7 101.607813 15.7 \r\nL 46.65 15.7 \r\nQ 44.65 15.7 44.65 17.7 \r\nL 44.65 46.05625 \r\nQ 44.65 48.05625 46.65 48.05625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\">\r\n     <path d=\"M 48.65 23.798437 \r\nL 68.65 23.798437 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\"/>\r\n    <g id=\"text_16\">\r\n     <!-- real -->\r\n     <defs>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <g transform=\"translate(76.65 27.298437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"41.082031\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"102.605469\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"163.884766\" xlink:href=\"#DejaVuSans-108\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"PathCollection_2\">\r\n     <g>\r\n      <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.65\" xlink:href=\"#mcccaa5c4df\" y=\"39.351562\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_17\">\r\n     <!-- pred -->\r\n     <defs>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n     </defs>\r\n     <g transform=\"translate(76.65 41.976562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"104.558594\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"166.082031\" xlink:href=\"#DejaVuSans-100\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p16606ca04b\">\r\n   <rect height=\"434.88\" width=\"558\" x=\"39.65\" y=\"10.7\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "text/plain": "<Figure size 720x576 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section we visualize the results for a random test case. (from validation data)\n",
    "\"\"\"\n",
    "x_std = np.std(data, axis=0)\n",
    "x_mean = np.mean(data, axis=0)\n",
    "y_std = np.std(labels, axis=0)\n",
    "y_mean = np.mean(labels, axis=0)\n",
    "normalized = (data - x_mean) / x_std\n",
    "\n",
    "i = 2605\n",
    "example = normalized[i]\n",
    "\n",
    "for j in range(20):\n",
    "    pred = model.predict(example[j:, :].reshape(-1, 20, 5))\n",
    "    example = np.concatenate((example, pred), axis=0)\n",
    "un_example = example * y_std + y_mean\n",
    "\n",
    "plt.plot(range(20), list(data[i, :, 3]))\n",
    "plt.scatter(range(20,40), list(un_example[20:, 0]), s=6, label='pred')\n",
    "plt.plot(range(20,40), list(data[20+i, :, 3]), label='real')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}